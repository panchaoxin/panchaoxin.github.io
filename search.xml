<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>HDFS JavaAPI</title>
      <link href="/2019/02/21/hadoop/HDFS-JavaAPI/"/>
      <url>/2019/02/21/hadoop/HDFS-JavaAPI/</url>
      
        <content type="html"><![CDATA[<p>1</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
          <category> HDFS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>HDFS JavaAPI2</title>
      <link href="/2019/02/21/HDFS-JavaAPI2/"/>
      <url>/2019/02/21/HDFS-JavaAPI2/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 配置文件详解</title>
      <link href="/2019/02/20/hadoop/Hadoop-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/20/hadoop/Hadoop-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="1-决定各个服务组件在哪台服务器运行的配置"><a href="#1-决定各个服务组件在哪台服务器运行的配置" class="headerlink" title="1. 决定各个服务组件在哪台服务器运行的配置"></a>1. 决定各个服务组件在哪台服务器运行的配置</h1><h2 id="1-1-NameNode"><a href="#1-1-NameNode" class="headerlink" title="1.1. NameNode"></a>1.1. NameNode</h2><p>etc/hadoop/core-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 决定NameNode位于哪个主机，服务监听哪个端口 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="1-2-DataNode"><a href="#1-2-DataNode" class="headerlink" title="1.2. DataNode"></a>1.2. DataNode</h2><p>etc/hadoop/slaves</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 一行代表一个datanode所在主机</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h2 id="1-3-SecondaryNameNode"><a href="#1-3-SecondaryNameNode" class="headerlink" title="1.3. SecondaryNameNode"></a>1.3. SecondaryNameNode</h2><p>hdfs-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- SecondaryNameNode的HTTP服务位于哪个主机，监听哪个端口 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- SecondaryNameNode的HTTPS服务位于哪个主机，监听哪个端口 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.https-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:50091<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="1-4-ResourceManager"><a href="#1-4-ResourceManager" class="headerlink" title="1.4. ResourceManager"></a>1.4. ResourceManager</h2><p>yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ResourceManager所在主机 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="1-5-NodeManager"><a href="#1-5-NodeManager" class="headerlink" title="1.5. NodeManager"></a>1.5. NodeManager</h2><p>yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NodeManager所在主机 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="1-6-MapReduce-JobHistory"><a href="#1-6-MapReduce-JobHistory" class="headerlink" title="1.6. MapReduce JobHistory"></a>1.6. MapReduce JobHistory</h2><p>mapred-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- JobHistory IPC服务 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- JobHistory Web UI HTTP服务 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- JobHistory Web UI HTTPS服务 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.https.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:19890<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 组件启动关闭的三种方式</title>
      <link href="/2019/02/20/hadoop/Hadoop%20%E7%BB%84%E4%BB%B6%E5%90%AF%E5%8A%A8%E5%85%B3%E9%97%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
      <url>/2019/02/20/hadoop/Hadoop%20%E7%BB%84%E4%BB%B6%E5%90%AF%E5%8A%A8%E5%85%B3%E9%97%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Hadoop2组件启动关闭的三种方式"><a href="#1-Hadoop2组件启动关闭的三种方式" class="headerlink" title="1. Hadoop2组件启动关闭的三种方式"></a>1. Hadoop2组件启动关闭的三种方式</h1><h2 id="1-1-方式一：各服务守护进程逐一启动关闭"><a href="#1-1-方式一：各服务守护进程逐一启动关闭" class="headerlink" title="1.1. 方式一：各服务守护进程逐一启动关闭"></a>1.1. 方式一：各服务守护进程逐一启动关闭</h2><p>在各节点上执行开启关闭自己的服务</p><ul><li>例如：namenode节点执行 hadoop-daemon.sh start|stop namenode</li><li>例如：datanode 节点执行 hadoop-daemon.sh start|stop datanode</li></ul><p>hdfs服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start|stop namenode|datanode|secondarynamenode</span><br></pre></td></tr></table></figure><p>yarn服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start|stop resourcemanager|nodemanager</span><br></pre></td></tr></table></figure><p>mapreduce服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start|stop historyserver</span><br></pre></td></tr></table></figure><h2 id="1-2-方式二：各个服务组件逐一启动关闭"><a href="#1-2-方式二：各个服务组件逐一启动关闭" class="headerlink" title="1.2. 方式二：各个服务组件逐一启动关闭"></a>1.2. 方式二：各个服务组件逐一启动关闭</h2><p>hdfs服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 只能在namenode执行以下命令（datanode、secondarynamenode没有权限）</span><br><span class="line">start-dfs.sh     # 启动 namenode、datanode、secondarynamenode</span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure><p>yarn服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 只能在resourcemanager执行以下命令（nodemanager没有权限）</span><br><span class="line">start-yarn.sh  # 启动 resourcemanager、nodemanager</span><br><span class="line">stop-yarn.sh</span><br></pre></td></tr></table></figure><p>mapreduce服务：因为只有一个守护进程，所以就是使用 mr-jobhistory-daemon.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start|stop historyserver</span><br></pre></td></tr></table></figure><h2 id="1-3-方式三：HDFS-YARN联合启动关闭"><a href="#1-3-方式三：HDFS-YARN联合启动关闭" class="headerlink" title="1.3. 方式三：HDFS+YARN联合启动关闭"></a>1.3. 方式三：HDFS+YARN联合启动关闭</h2><p>hdfs + yarn服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh# 相当于先后执行 start-dfs.sh 和 start-yarn.sh</span><br><span class="line">stop-all.sh# 相当于先后执行 stop-dfs.sh 和 stop-yarn.sh</span><br></pre></td></tr></table></figure><p>mapreduce服务：单独使用mr-jobhistory-daemon.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start|stop historyserver</span><br></pre></td></tr></table></figure><p>注意：start-all.sh/stop-all.sh 不建议使用。因为执行的前提是当前节点即是namenode，又是resourcemanager。但是实际不可能将namenode和resourcemanager放在一个节点上，倘若这个节点挂了，那么HDFS和YARN就都挂了。</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>HDFS 概述</title>
      <link href="/2019/02/20/hadoop/HDFS%20%E6%A6%82%E8%BF%B0/"/>
      <url>/2019/02/20/hadoop/HDFS%20%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是HDFS"><a href="#1-什么是HDFS" class="headerlink" title="1. 什么是HDFS"></a>1. 什么是HDFS</h1><h2 id="1-1-HDFS特点"><a href="#1-1-HDFS特点" class="headerlink" title="1.1. HDFS特点"></a>1.1. HDFS特点</h2><p>HDFS以流式数据访问模式来存储超大文件，运行于商用硬件集群上。</p><blockquote><ul><li><strong>支持超大文件</strong>  “超大文件”在这里指具有几百MB、几百GB甚至几百TB大小的文件。目前已经有存储PB级数据的Hadoop集群了</li><li><strong>实现流式数据访问</strong>  HDFS的构建思路是这样的：一次写入、多次读取是&gt;最高效的访问模式。数据集通常由数据源生成或从数据源复制而来，接着长时间在此数据集上进行各种分析。每次分析都将涉及该数据集的大部分数据甚至全部，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。</li><li><strong>兼容廉价的商用硬件</strong>  Hadoop并不需要运行在昂贵且髙可靠的硬件上。它是设计运行在商用硬件(在各种零售店都能买到的普通硬件)的集群上的，因此至少对于庞大的集群来说，节点故障的几率还是非常髙的。HDFS遇到上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断。</li><li><strong>支持简单的文件模型</strong>  Hadoop对文件进行了简化，牺牲了一定的性能，但是获得了批量处理的特性，能快速处理批量数据集，只允许追加，不允许修改。</li><li><strong>强大的跨平台兼容性</strong>  Hadoop是基于Java开发的，具有很好的跨平台特性</li></ul></blockquote><h3 id="1-1-1-HDFS优点："><a href="#1-1-1-HDFS优点：" class="headerlink" title="1.1.1. HDFS优点："></a>1.1.1. HDFS优点：</h3><blockquote><ul><li>高容错性<ul><li>数据自动保存多个副本</li><li>副本丢失后，自动恢复</li></ul></li><li>适合批处理<ul><li>移动计算而非数据</li><li>数据位置暴露给计算框架</li></ul></li><li>适合大数据处理<ul><li>GB、TB、甚至PB级</li><li>百万规模以上的文件数量</li><li>10K+节点</li></ul></li><li>可构建在廉价机器上<ul><li>通过多副本提高可靠性</li><li>提供了容错和恢复机制</li></ul></li></ul></blockquote><h3 id="1-1-2-HDFS缺点"><a href="#1-1-2-HDFS缺点" class="headerlink" title="1.1.2. HDFS缺点"></a>1.1.2. HDFS缺点</h3><blockquote><ul><li>低延迟数据访问<ul><li>比如毫秒级</li><li>低延迟与高吞吐率</li></ul></li><li>小文件存取<ul><li>占用NameNode大量内存</li><li>寻道时间超过读取时间</li></ul></li><li>并发写入、文件随机修改<ul><li>一个文件只能有一个写者</li><li>仅支持append</li></ul></li></ul></blockquote><h1 id="2-HDFS架构"><a href="#2-HDFS架构" class="headerlink" title="2. HDFS架构"></a>2. HDFS架构</h1><p><img src="https://img-blog.csdn.net/20170508095655559" alt></p><p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1550675820437&amp;di=a9857584c45f7b44c5c5d84619ead42c&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180619%2F56205dd7f8214fa4a0662176f1d30776.jpg" alt></p><h2 id="2-1-HDFS数据单元：数据块"><a href="#2-1-HDFS数据单元：数据块" class="headerlink" title="2.1. HDFS数据单元：数据块"></a>2.1. HDFS数据单元：数据块</h2><p>数据以block形式存储。一个block在磁盘上对应两个文件，一个是数据本身，一个是块的元数据（包含数据块长度、校验和、时间戳）</p><p>注意HDFS中有两种元数据：</p><ul><li>数据块元数据：存放在DataNode上，包含数据块长度、校验和、时间戳</li><li>文件元数据：存放在NameNode上，包含文件名、文件目录结构、文件的块副本数、文件的时间戳、文件权限、文件的数据块列表以及各个块所在DataNode等信息</li></ul><h3 id="2-1-1-块大小"><a href="#2-1-1-块大小" class="headerlink" title="2.1.1. 块大小"></a>2.1.1. 块大小</h3><ul><li><p>Hadoop2.0中，块大小默认为64M</p></li><li><p>Hadoop2.0中，块大小默认为128M。例如：200MB的文件要分为2块，分为128M + 72M</p></li></ul><h3 id="2-1-2-数据块为什么这么大"><a href="#2-1-2-数据块为什么这么大" class="headerlink" title="2.1.2. 数据块为什么这么大?"></a>2.1.2. 数据块为什么这么大?</h3><p>减少硬盘寻道时间(disk seek time)</p><blockquote><p>HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。因而，传输一个由多个块组成的大文件的时间取决于磁盘传输速率。</p></blockquote><p>减少Namenode内存消耗</p><blockquote><p> 对于HDFS，他只有一个Namenode节点，他的内存相对于Datanode来说，是极其有限的。然而，namenode需要在其内存FSImage文件中中记录在Datanode中的数据块信息，假如数据块大小设置过少，而需要维护的数据块信息就会过多，那Namenode的内存可能就会伤不起了</p></blockquote><h3 id="2-1-3-数据块为什么不能过大"><a href="#2-1-3-数据块为什么不能过大" class="headerlink" title="2.1.3. 数据块为什么不能过大"></a>2.1.3. 数据块为什么不能过大</h3><p>Map崩溃问题</p><blockquote><p>系统需要重新启动，启动过程需要重新加载数据，数据块越大，数据加载时间越长，系统恢复过程越长</p></blockquote><p>监管时间问题</p><blockquote><p>主节点监管其他节点的情况，每个节点会周期性的把完成的工作和状态的更新报告回来。如果一个节点保持沉默超过一个预设的时间间隔，主节点记录下这个节点状态为死亡，并把分配给这个节点的数据发到别的节点。对于这个“预设的时间间隔”，这是从数据块的角度大概估算的。假如是对于64MB的数据块，我可以假设你10分钟之内无论如何也能解决了吧，超过10分钟也没反应，那就是死了。可对于640MB或是1G以上的数据，我应该要估算个多长的时间内？估算的时间短了，那就误判死亡了，分分钟更坏的情况是所有节点都会被判死亡。估算的时间长了，那等待的时间就过长了。所以对于过大的数据块，这个“预设的时间间隔”不好估算</p></blockquote><p>MapReduce问题分解问题</p><blockquote><p>数据块过大会导致MapReduce就一两个任务执行完全牺牲了MapReduce的并行度，发挥不了分布式并行处理的效果。</p></blockquote><p>约束Map输出</p><blockquote><p>在MapReduce框架里，Map之后的数据是要经过排序才执行Reduce操作的。想想归并排序算法的思想，对小文件进行排序，然后将小文件归并成大文件的思想。如果数据块很大，排序就变慢了。</p></blockquote><h3 id="2-1-4-数据块副本"><a href="#2-1-4-数据块副本" class="headerlink" title="2.1.4. 数据块副本"></a>2.1.4. 数据块副本</h3><p>每个块有多个副本，存储在不同的DataNode上。副本数默认为3</p><h3 id="2-1-5-数据块副本存放策略"><a href="#2-1-5-数据块副本存放策略" class="headerlink" title="2.1.5. 数据块副本存放策略"></a>2.1.5. 数据块副本存放策略</h3><p>假设数据块有三个副本：</p><ul><li><p>第一个副本：放置在本地机架的节点上（就近原则）；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点</p></li><li><p>第二个副本：放置在与第一个副本不同的机架的节点上。因为同一个机架一般使用同一个电源，电源挂掉则整个机架的服务器都挂掉。所以要放在另一个机架的节点上。</p></li><li><p>第三个副本：与第二个副本相同机架的其他节点上。因为前2个副本已经分别存放在位于两个不同机架的节点上，安全性已经得到一定的保证。同一个机架的节点一般连接同一个高速交换机，所以现在把第3个副本放到与第2个副本相同的机架上，还保证了数据的快速传输。</p></li></ul><p><img src="https://i.loli.net/2019/02/21/5c6e35f21d63c.png" alt></p><p>如果有更多的其它副本：则挑选随机节点</p><h3 id="2-1-6-数据块损坏（corruption）处理"><a href="#2-1-6-数据块损坏（corruption）处理" class="headerlink" title="2.1.6. 数据块损坏（corruption）处理"></a>2.1.6. 数据块损坏（corruption）处理</h3><p>情况1：client读取数据时</p><ul><li>客户端请求DataNode读取数据块，DataNode读取block时，会计算该block的checksum</li><li>如果计算得到的checksum，与block创建时的值不一样，说明block已经损坏</li><li>client得知该block已经损坏，会读取其它DataNode上的副本块</li><li>下一次DataNode向NameNode发送块列表报告时，NameNode得知该数据块已经损坏，会复制该block的副本，达到预设的副本数</li></ul><p>情况2：DataNode会自动在其文件创建后三周验证其checksum，处理同上。</p><h3 id="2-1-7-验证每个数据块有两个文件"><a href="#2-1-7-验证每个数据块有两个文件" class="headerlink" title="2.1.7. 验证每个数据块有两个文件"></a>2.1.7. 验证每个数据块有两个文件</h3><p><code>dfs/data/</code> 是HDFS数据的存储路径。可以看到每个数据块有两份文件，一个是数据本身，一个是元数据。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tree /usr/local/hadoop/tmp/dfs/data/</span><br><span class="line">/usr/local/hadoop/tmp/dfs/data/</span><br><span class="line">├── current</span><br><span class="line">│   ├── BP-798495748-192.168.57.100-1550512504378</span><br><span class="line">│   │   ├── current</span><br><span class="line">│   │   │   ├── dfsUsed</span><br><span class="line">│   │   │   ├── finalized</span><br><span class="line">│   │   │   │   └── subdir0</span><br><span class="line">│   │   │   │       └── subdir0</span><br><span class="line">│   │   │   │           ├── blk_1073741825   # 数据文件</span><br><span class="line">│   │   │   │           ├── blk_1073741825_1003.meta  # 元数据文件</span><br><span class="line">│   │   │   │           ├── blk_1073741826</span><br><span class="line">│   │   │   │           ├── blk_1073741826_1004.meta</span><br><span class="line">│   │   │   │           ├── blk_1073741827</span><br><span class="line">│   │   │   │           └── blk_1073741827_1005.meta</span><br><span class="line">│   │   │   ├── rbw</span><br><span class="line">│   │   │   └── VERSION</span><br><span class="line">│   │   ├── dncp_block_verification.log.curr</span><br><span class="line">│   │   ├── dncp_block_verification.log.prev</span><br><span class="line">│   │   └── tmp</span><br><span class="line">│   └── VERSION</span><br><span class="line">└── in_use.lock</span><br></pre></td></tr></table></figure><h2 id="2-2-HDFS命名空间管理"><a href="#2-2-HDFS命名空间管理" class="headerlink" title="2.2. HDFS命名空间管理"></a>2.2. HDFS命名空间管理</h2><p>HDFS的命名空间包含目录、文件和数据块</p><p><img src="https://i.loli.net/2019/02/20/5c6d40bcce6ec.png" alt></p><p>HDFS使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等。</p><p>注意：只能在文件中追加信息，但是不能修改文件内容。</p><h2 id="2-3-NameNode（NN）"><a href="#2-3-NameNode（NN）" class="headerlink" title="2.3. NameNode（NN）"></a>2.3. NameNode（NN）</h2><p>NameNode是整个HDFS的管家</p><ul><li>管理整个HDFS的元数据（MetaData）</li><li>管理客户端对HDFS的访问。客户端读写数据实际是自己到DataNode上操作的，但是要先与NameNode交互，得到元数据信息（数据在哪些DataNode上）。<strong>NameNode会根据全局情况做出决定，客户端读取数据时，NameNode尽量让客户端读取最近的副本</strong>。</li><li>决定数据块副本存放在哪些DataNode上。</li><li>周期性从每个DataNode接收心跳信号和块状态报告（BlockReport）。块状态报告包含了该DataNode上所有的数据块列表信息。</li></ul><p>NameNode保存了两个核心的数据结构，即FsImage（保存HDFS元数据）和EditLog（保存HDFS操作日志）</p><ul><li>FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据-</li><li>EditLog中记录了所有针对文件的创建、删除、重命名等操作</li></ul><p><img src="https://i.loli.net/2019/02/20/5c6d43ce953fd.png" alt></p><h3 id="2-3-1-FsImage和EditLog"><a href="#2-3-1-FsImage和EditLog" class="headerlink" title="2.3.1. FsImage和EditLog"></a>2.3.1. FsImage和EditLog</h3><p>元数据在NameNode内存中有一份，同时还要写到磁盘上，文件名为FsImage</p><p>FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据。</p><p>FsImage文件没有记录块存储在哪个数据节点。而是由名称节点把这些映射保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，直接加载到NameNode的内存中，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。</p><p>元数据发生改变时，不会立即同步到FsImage文件，而是在edits记录元数据的操作日志。经过一段时间后，再由SecondaryNameNode将edits中的内容合并到FsImage中</p><h3 id="2-3-2-NameNode需要格式化"><a href="#2-3-2-NameNode需要格式化" class="headerlink" title="2.3.2. NameNode需要格式化"></a>2.3.2. NameNode需要格式化</h3><p>NameNode一开始需要格式化，目的是生成FsImage</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><h3 id="2-3-3-NameNode启动过程"><a href="#2-3-3-NameNode启动过程" class="headerlink" title="2.3.3. NameNode启动过程"></a>2.3.3. NameNode启动过程</h3><p>NameNode启动过程：</p><ul><li>读取fsimage和editlog到内存中</li><li>执行editlog的各项操作，更新内存中的元数据，存在内存中的元数据支持客户端的读操作</li><li>将内存中的元数据写到新的fsimage文件中</li><li>创建一个新的空的editlog文件。<strong>同时启动HDFS的安全模式</strong></li><li>启动DataNode<ul><li>向NameNode注册</li><li>发送BlockReport。发送完之后，<strong>关闭HDFS的安全模式</strong>。</li></ul></li><li>之后HDFS的所有操作都记录到新的editlog中</li></ul><p>HDFS的安全模式（SafeMode）：</p><ul><li>等待DataNode向NameNode发送BlockReport。在安全模式期间，客户端只能读取HDFS，但是不能写HDFS（创建文件夹、上传文件、删除文件 都不能操作）。</li><li>汇总所有的BlockReport。一开始NameNode加载完fsimage和editlog时，就得知整个文件系统总共有多少个block（total blocks）。从不断接收到的BlockReport中，不断累计得到所有的DataNode上总共有多少block（reported blocks）。计算 reported blocks / total blocks，如果比值 &gt;= 99.9%，安全模式才会退出。</li><li>安全模式退出后，客户端就能对HDFS执行写操作了。</li></ul><h3 id="2-3-4-验证安全模式的存在"><a href="#2-3-4-验证安全模式的存在" class="headerlink" title="2.3.4. 验证安全模式的存在"></a>2.3.4. 验证安全模式的存在</h3><p>关闭HDFS所有服务，只启动namenode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><p>查看namenode的web ui，可以看到NameNode处于SafeMode。</p><ul><li>total blocks有3个，接收到的reported blocks只有0个</li><li>只有当 reported blocks / total blocks &gt;= 0.9990，才会关闭SafeMode</li></ul><p><img src="https://i.loli.net/2019/02/21/5c6e3705a5ac9.png" alt></p><p>启动datanode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure><p>启动后，在短时间内再次查看namenode的web ui，可以看到NameNode仍处于SafeMode。total blocks有3个，接收到的reported blocks也有3个，所以 reported blocks / total blocks = 1 &gt;= 0.9990，已经触发了关闭SafeMode的条件。因此在30秒之后，NameNode将自动关闭SafeMode</p><p><img src="https://i.loli.net/2019/02/21/5c6e37bad63d6.png" alt></p><p>经过30秒后，再次查看namenode的web ui</p><p><img src="https://i.loli.net/2019/02/21/5c6e38ebbf911.png" alt></p><h3 id="2-3-5-为什么达到关闭SafeMode的条件，还要缓冲30秒？"><a href="#2-3-5-为什么达到关闭SafeMode的条件，还要缓冲30秒？" class="headerlink" title="2.3.5. 为什么达到关闭SafeMode的条件，还要缓冲30秒？"></a>2.3.5. 为什么达到关闭SafeMode的条件，还要缓冲30秒？</h3><p>服务器求稳不求快，给30秒让HDFS稳定一下</p><h2 id="2-4-DataNode"><a href="#2-4-DataNode" class="headerlink" title="2.4. DataNode"></a>2.4. DataNode</h2><ul><li>负责数据的存储和读写</li><li>DataNode启动后向NameNode注册，通过后，周期性（1小时）向NameNode上报块列表信息</li><li>每3秒一次向NameNode发送心跳，心跳返回结果带有NameNode给DataNode命令（如复制块数据到另一台机器，或删除某个数据块）。如果NameNode超过10分钟没有收到某个DataNode，则认为该DataNode不可用。</li></ul><h2 id="2-5-SecondaryNameNode（SNN）"><a href="#2-5-SecondaryNameNode（SNN）" class="headerlink" title="2.5. SecondaryNameNode（SNN）"></a>2.5. SecondaryNameNode（SNN）</h2><p>SecondaryNameNode的作用：</p><ul><li>辅助NameNode合并fsimage和editlog</li><li>辅助合并fsimage和editlog时，会在本地保留一份fsimage.ckpt，所以还起到元数据冷备份的作用</li></ul><p>即使SecondaryNameNode不启动，HDFS也能正常工作</p><h3 id="2-5-1-为什么要辅助NameNode合并fsimage和editlog"><a href="#2-5-1-为什么要辅助NameNode合并fsimage和editlog" class="headerlink" title="2.5.1. 为什么要辅助NameNode合并fsimage和editlog"></a>2.5.1. 为什么要辅助NameNode合并fsimage和editlog</h3><p>假如HDFS起来之后，几个月都没有停止、重启。如果操作了很多数据，editlog就会非常大，下一次NameNode重启时，读取editlog要花很多时间。</p><p>此时就需要SecondaryNameNode，每隔一段时间（当然触发情况不止是这一个），就去帮助NameNode合并fsimage和editlog，生成新的fsimage，再把新的fsimage复制给NameNode。</p><p>这样下一次NameNode重启时，editlog就不会特别大，读取editlog不用花太多时间，就加快了NameNode的启动时间。</p><h3 id="2-5-2-SecondaryNameNode触发合并的情况"><a href="#2-5-2-SecondaryNameNode触发合并的情况" class="headerlink" title="2.5.2. SecondaryNameNode触发合并的情况"></a>2.5.2. SecondaryNameNode触发合并的情况</h3><ul><li><p>情况1：根据配置文件设置的时间间隔fs.checkpoint.period 默认3600秒（1小时）。</p></li><li><p>情况2：根据配置文件设置EditsLog大小 fs.checkpoint.size 规定edits文件的最大值默认是64MB</p></li></ul><h3 id="2-5-3-合并流程"><a href="#2-5-3-合并流程" class="headerlink" title="2.5.3. 合并流程"></a>2.5.3. 合并流程</h3><p><img src="https://i.loli.net/2019/02/21/5c6e2c8bd5253.png" alt></p><ol><li><p>当edits文件的大小达到一个临界值(默认是64MB)或者间隔一段时间(默认是1小时)的时候checkpoint会触发SecondaryNameNode进行合并工作。</p></li><li><p>当触发一个checkpoint操作时，NameNode会生成一个新的edits即上图中的edits.new文件，之后元数据的改变都会写入edits.new文件中，而不是原来的edits文件。</p></li><li><p>SecondaryNameNode会将NameNode的edits文件和FsImage下载到本地。</p></li><li><p>SecondaryNameNode将本地的FsImage文件加载到内存中，然后再与edits文件进行合并生成一个新的FsImage文件即上图中的FsImage.ckpt文件。</p></li><li><p>SecondaryNameNode将新生成的FsImage.ckpt文件发送到NameNode节点。</p></li><li><p>NameNode结点的edits.new文件和FsImage.ckpt文件会替换掉原来的edits文件和FsImage文件，至此，刚好是一个轮回即在NameNode中又是edits和FsImage文件了。</p></li><li><p>等待下一次checkpoint触发SecondaryNameNode进行工作，一直这样循环操作。</p><p>以上过程既实现了FsImage和EditsLog的合并。因为其间名称节点的元数据被拷贝到第二名称节点上，所以说起到冷备份的效果。</p></li></ol><h1 id="3-HDFS安全机制"><a href="#3-HDFS安全机制" class="headerlink" title="3. HDFS安全机制"></a>3. HDFS安全机制</h1><h2 id="3-1-HDFS副本"><a href="#3-1-HDFS副本" class="headerlink" title="3.1. HDFS副本"></a>3.1. HDFS副本</h2>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
          <category> HDFS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce 概述</title>
      <link href="/2019/02/20/hadoop/MapReduce%20%E6%A6%82%E8%BF%B0/"/>
      <url>/2019/02/20/hadoop/MapReduce%20%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h1><p><img src="http://static.zybuluo.com/zhangyy/guh3ya1ei4mfdbg6h07sgokp/image_1b2tjc5511tr410v10r1g9u869m.png" alt></p><p>ResourceManager</p><ul><li>处理客户端请求</li><li>启动/监控ApplicationMaster</li><li>监控NodeManager</li><li>资源分配与调度</li></ul><p>NodeManager</p><ul><li>单个节点上的资源管理</li><li>处理来自ResourceManager的命令</li><li>处理来自ApplicationMaster的命令</li></ul><p>ApplicationMaster</p><ul><li>数据切分</li><li>为应用程序申请资源，并分配给内部任务</li><li>任务监控与容错</li></ul><p>Container</p><ul><li>对任务运行环境的抽象，封装了CPU内存等多维资源以及环境变量、启动命令等任务运  行相关的信息.</li></ul><h1 id="MapReduce架构"><a href="#MapReduce架构" class="headerlink" title="MapReduce架构"></a>MapReduce架构</h1><p>离线计算框架 MapReduce</p><ol><li>将计算过程分为两个阶段，map和reduce<ul><li>map 阶段并行处理输入数据</li><li>reduce 阶段对map 结果进行汇总。</li></ul></li><li>shuffle 连接map 和Reduce 两个阶段<ul><li>map task 将数据写到本地磁盘</li><li>reduce task 从每个map TASK 上读取一份数据</li></ul></li><li>仅适合 离线批处理<ul><li>具有很好的容错性和扩展性</li><li>适合简单的批处理任务</li></ul></li><li>缺点明显<ul><li>启动开销大，过多使用磁盘导致效率底下等。</li></ul></li></ol><h1 id="MapReduce-On-YARN"><a href="#MapReduce-On-YARN" class="headerlink" title="MapReduce On YARN"></a>MapReduce On YARN</h1><p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1550676718597&amp;di=725928c0922f203e376f78e7ba834d2e&amp;imgtype=0&amp;src=http%3A%2F%2Fstatic.zybuluo.com%2Fzhangyy%2F6oykq4tguvh2n5ieoid393qy%2Fimage_1b2tjmaq41vni1nk1unr1ghg70q13.png" alt></p><ol><li><p>客户端向YARN中提交应用程序/作业给ResourceManager，其中包括ApplicaitonMaster程序、启动ApplicationMaster的命令、用户程序等；</p></li><li><p>ResourceManager为作业分配第一个Container，并与对应的NodeManager通信，要求它在这个Containter中启动该作业的ApplicationMaster（App Mstr）；</p></li><li><p>ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查询作业的运行状态；然后它将为各个任务申请资源并监控任务的运行状态，直到运行结束。即重复步骤4-7；</p></li><li><p>ApplicationMaster采用轮询的方式通过RPC请求向ResourceManager申请和领取资源；</p></li><li><p>一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务；</p></li><li><p>各个NodeManager分别在Container中启动Map任务（Map Task），或者启动Reduce任务（Reduce Task），或者都启动（如果本机资源足够的话）；</p></li><li><p>各个任务通过RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicaitonMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；<br>在作业运行过程中，用户可随时通过RPC向ApplicationMaster查询作业当前运行状态；</p></li><li><p>作业完成后，ApplicationMaster向ResourceManager注销并关闭自己；</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
          <category> MapReduce </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 概述</title>
      <link href="/2019/02/20/hadoop/Hadoop%20%E6%A6%82%E8%BF%B0/"/>
      <url>/2019/02/20/hadoop/Hadoop%20%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是hadoop"><a href="#1-什么是hadoop" class="headerlink" title="1. 什么是hadoop"></a>1. 什么是hadoop</h1><p>hadoop是一个分布式系统基础架构，由apache基金会开发，用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力高速运算和存储</p><h2 id="1-1-hadoop核心组件"><a href="#1-1-hadoop核心组件" class="headerlink" title="1.1. hadoop核心组件"></a>1.1. hadoop核心组件</h2><p>它包括三部分：HDFS，YARN，和MapReduce</p><table><thead><tr><th>组件</th><th>描述</th><th>功能</th></tr></thead><tbody><tr><td>HDFS</td><td>Hadoop分布式文件系统</td><td>分布式存储海量数据集</td></tr><tr><td>MapReduce</td><td>基于YARN分布式并行处理海量数据集</td><td>分布式计算海量数据集</td></tr><tr><td>YARN</td><td>任务调度和集群资源管理框架</td><td>任务调度、资源管理</td></tr></tbody></table><h2 id="1-2-hadoop狭义与广义"><a href="#1-2-hadoop狭义与广义" class="headerlink" title="1.2. hadoop狭义与广义"></a>1.2. hadoop狭义与广义</h2><p>狭义hadoop：大数据分布式存储（HDFS） + 分布式计算 + 资源调度（YARN）平台。</p><p>广义hadoop：指hadoop生态系统。hadoop是其中最重要最基础的一个部分。生态系统中的每一个子系统只能解决某一个领域的特定问题域。</p><p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1550669228176&amp;di=84caedf6ac9ac91d3ecf95bd3006fa1c&amp;imgtype=jpg&amp;src=http%3A%2F%2Fimg4.imgtn.bdimg.com%2Fit%2Fu%3D4179503434%2C449336090%26fm%3D214%26gp%3D0.jpg" alt></p><blockquote><p>HDFS：分布式文件系统<br>MapReduce：分布式运算程序开发框架<br>Hbase：基于HADOOP的分布式海量数据库，离线分析和在线业务通吃<br>Hive：基于大数据技术（文件系统+运算框架）的SQL数据仓库工具，使用方便，功能丰富，基于MR延迟大<br>Sqoop：数据导入导出工具<br>Flume：数据采集框架<br>ZOOKEEPER：分布式协调服务基础组件<br>Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库<br>Oozie：工作流调度框架<br>Sqoop：数据导入导出工具<br>Flume：日志数据采集框架</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>文章标题</title>
      <link href="/2019/02/19/%E6%96%87%E7%AB%A0%E6%A0%87%E9%A2%98/"/>
      <url>/2019/02/19/%E6%96%87%E7%AB%A0%E6%A0%87%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-这里是文章内容"><a href="#1-这里是文章内容" class="headerlink" title="1. 这里是文章内容"></a>1. 这里是文章内容</h1><h2 id="1-1-这里是文章内容"><a href="#1-1-这里是文章内容" class="headerlink" title="1.1 这里是文章内容"></a>1.1 这里是文章内容</h2><blockquote><p>这里是文章内容<br>这里是文章内容</p></blockquote><p><a href="https://www.baidu.com" target="_blank" rel="noopener">haha</a><br><img src="/images/avatar.gif" alt><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br></pre></td></tr></table></figure></p><h1 id="这里是文章内容"><a href="#这里是文章内容" class="headerlink" title="这里是文章内容"></a>这里是文章内容</h1><h2 id="这里是文章内容-1"><a href="#这里是文章内容-1" class="headerlink" title="这里是文章内容"></a>这里是文章内容</h2><blockquote><p>这里是文章内容<br>这里是文章内容</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br></pre></td></tr></table></figure><h1 id="这里是文章内容-2"><a href="#这里是文章内容-2" class="headerlink" title="这里是文章内容"></a>这里是文章内容</h1><h2 id="这里是文章内容-3"><a href="#这里是文章内容-3" class="headerlink" title="这里是文章内容"></a>这里是文章内容</h2><blockquote><p>这里是文章内容<br>这里是文章内容</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br></pre></td></tr></table></figure><h1 id="这里是文章内容-4"><a href="#这里是文章内容-4" class="headerlink" title="这里是文章内容"></a>这里是文章内容</h1><h2 id="这里是文章内容-5"><a href="#这里是文章内容-5" class="headerlink" title="这里是文章内容"></a>这里是文章内容</h2><blockquote><p>这里是文章内容<br>这里是文章内容</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br><span class="line">这里是文章内容</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
