<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HDFS JavaAPI]]></title>
    <url>%2F2019%2F02%2F21%2Fhadoop%2FHDFS-JavaAPI%2F</url>
    <content type="text"></content>
      <categories>
        <category>Hadoop</category>
        <category>HDFS</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HDFS JavaAPI2]]></title>
    <url>%2F2019%2F02%2F21%2FHDFS-JavaAPI2%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 配置文件详解]]></title>
    <url>%2F2019%2F02%2F20%2Fhadoop%2FHadoop-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. 决定各个服务组件在哪台服务器运行的配置1.1. NameNodeetc/hadoop/core-site.xml 12345&lt;property&gt; &lt;!-- 决定NameNode位于哪个主机，服务监听哪个端口 --&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;&lt;/property&gt; 1.2. DataNodeetc/hadoop/slaves 123# 一行代表一个datanode所在主机slave1slave2 1.3. SecondaryNameNodehdfs-site.xml 12345678910&lt;property&gt; &lt;!-- SecondaryNameNode的HTTP服务位于哪个主机，监听哪个端口 --&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:50090&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;!-- SecondaryNameNode的HTTPS服务位于哪个主机，监听哪个端口 --&gt; &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt; &lt;value&gt;0.0.0.0:50091&lt;/value&gt;&lt;/property&gt; 1.4. ResourceManageryarn-site.xml 12345&lt;property&gt; &lt;!-- ResourceManager所在主机 --&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt;&lt;/property&gt; 1.5. NodeManageryarn-site.xml 12345&lt;property&gt; &lt;!-- NodeManager所在主机 --&gt; &lt;name&gt;yarn.nodemanager.hostname&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt;&lt;/property&gt; 1.6. MapReduce JobHistorymapred-site.xml 123456789101112131415&lt;property&gt; &lt;!-- JobHistory IPC服务 --&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;0.0.0.0:10020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;!-- JobHistory Web UI HTTP服务 --&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;0.0.0.0:19888&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;!-- JobHistory Web UI HTTPS服务 --&gt; &lt;name&gt;mapreduce.jobhistory.webapp.https.address&lt;/name&gt; &lt;value&gt;0.0.0.0:19890&lt;/value&gt;&lt;/property&gt;]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 组件启动关闭的三种方式]]></title>
    <url>%2F2019%2F02%2F20%2Fhadoop%2FHadoop%20%E7%BB%84%E4%BB%B6%E5%90%AF%E5%8A%A8%E5%85%B3%E9%97%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1. Hadoop2组件启动关闭的三种方式1.1. 方式一：各服务守护进程逐一启动关闭在各节点上执行开启关闭自己的服务 例如：namenode节点执行 hadoop-daemon.sh start|stop namenode 例如：datanode 节点执行 hadoop-daemon.sh start|stop datanode hdfs服务： 1hadoop-daemon.sh start|stop namenode|datanode|secondarynamenode yarn服务： 1yarn-daemon.sh start|stop resourcemanager|nodemanager mapreduce服务： 1mr-jobhistory-daemon.sh start|stop historyserver 1.2. 方式二：各个服务组件逐一启动关闭hdfs服务： 123# 只能在namenode执行以下命令（datanode、secondarynamenode没有权限）start-dfs.sh # 启动 namenode、datanode、secondarynamenodestop-dfs.sh yarn服务： 123# 只能在resourcemanager执行以下命令（nodemanager没有权限）start-yarn.sh # 启动 resourcemanager、nodemanagerstop-yarn.sh mapreduce服务：因为只有一个守护进程，所以就是使用 mr-jobhistory-daemon.sh 1mr-jobhistory-daemon.sh start|stop historyserver 1.3. 方式三：HDFS+YARN联合启动关闭hdfs + yarn服务： 12start-all.sh # 相当于先后执行 start-dfs.sh 和 start-yarn.shstop-all.sh # 相当于先后执行 stop-dfs.sh 和 stop-yarn.sh mapreduce服务：单独使用mr-jobhistory-daemon.sh 1mr-jobhistory-daemon.sh start|stop historyserver 注意：start-all.sh/stop-all.sh 不建议使用。因为执行的前提是当前节点即是namenode，又是resourcemanager。但是实际不可能将namenode和resourcemanager放在一个节点上，倘若这个节点挂了，那么HDFS和YARN就都挂了。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HDFS 概述]]></title>
    <url>%2F2019%2F02%2F20%2Fhadoop%2FHDFS%20%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[1. 什么是HDFS1.1. HDFS特点HDFS以流式数据访问模式来存储超大文件，运行于商用硬件集群上。 支持超大文件 “超大文件”在这里指具有几百MB、几百GB甚至几百TB大小的文件。目前已经有存储PB级数据的Hadoop集群了 实现流式数据访问 HDFS的构建思路是这样的：一次写入、多次读取是&gt;最高效的访问模式。数据集通常由数据源生成或从数据源复制而来，接着长时间在此数据集上进行各种分析。每次分析都将涉及该数据集的大部分数据甚至全部，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。 兼容廉价的商用硬件 Hadoop并不需要运行在昂贵且髙可靠的硬件上。它是设计运行在商用硬件(在各种零售店都能买到的普通硬件)的集群上的，因此至少对于庞大的集群来说，节点故障的几率还是非常髙的。HDFS遇到上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断。 支持简单的文件模型 Hadoop对文件进行了简化，牺牲了一定的性能，但是获得了批量处理的特性，能快速处理批量数据集，只允许追加，不允许修改。 强大的跨平台兼容性 Hadoop是基于Java开发的，具有很好的跨平台特性 1.1.1. HDFS优点： 高容错性 数据自动保存多个副本 副本丢失后，自动恢复 适合批处理 移动计算而非数据 数据位置暴露给计算框架 适合大数据处理 GB、TB、甚至PB级 百万规模以上的文件数量 10K+节点 可构建在廉价机器上 通过多副本提高可靠性 提供了容错和恢复机制 1.1.2. HDFS缺点 低延迟数据访问 比如毫秒级 低延迟与高吞吐率 小文件存取 占用NameNode大量内存 寻道时间超过读取时间 并发写入、文件随机修改 一个文件只能有一个写者 仅支持append 2. HDFS架构 2.1. HDFS数据单元：数据块数据以block形式存储。一个block在磁盘上对应两个文件，一个是数据本身，一个是块的元数据（包含数据块长度、校验和、时间戳） 注意HDFS中有两种元数据： 数据块元数据：存放在DataNode上，包含数据块长度、校验和、时间戳 文件元数据：存放在NameNode上，包含文件名、文件目录结构、文件的块副本数、文件的时间戳、文件权限、文件的数据块列表以及各个块所在DataNode等信息 2.1.1. 块大小 Hadoop2.0中，块大小默认为64M Hadoop2.0中，块大小默认为128M。例如：200MB的文件要分为2块，分为128M + 72M 2.1.2. 数据块为什么这么大?减少硬盘寻道时间(disk seek time) HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。因而，传输一个由多个块组成的大文件的时间取决于磁盘传输速率。 减少Namenode内存消耗 对于HDFS，他只有一个Namenode节点，他的内存相对于Datanode来说，是极其有限的。然而，namenode需要在其内存FSImage文件中中记录在Datanode中的数据块信息，假如数据块大小设置过少，而需要维护的数据块信息就会过多，那Namenode的内存可能就会伤不起了 2.1.3. 数据块为什么不能过大Map崩溃问题 系统需要重新启动，启动过程需要重新加载数据，数据块越大，数据加载时间越长，系统恢复过程越长 监管时间问题 主节点监管其他节点的情况，每个节点会周期性的把完成的工作和状态的更新报告回来。如果一个节点保持沉默超过一个预设的时间间隔，主节点记录下这个节点状态为死亡，并把分配给这个节点的数据发到别的节点。对于这个“预设的时间间隔”，这是从数据块的角度大概估算的。假如是对于64MB的数据块，我可以假设你10分钟之内无论如何也能解决了吧，超过10分钟也没反应，那就是死了。可对于640MB或是1G以上的数据，我应该要估算个多长的时间内？估算的时间短了，那就误判死亡了，分分钟更坏的情况是所有节点都会被判死亡。估算的时间长了，那等待的时间就过长了。所以对于过大的数据块，这个“预设的时间间隔”不好估算 MapReduce问题分解问题 数据块过大会导致MapReduce就一两个任务执行完全牺牲了MapReduce的并行度，发挥不了分布式并行处理的效果。 约束Map输出 在MapReduce框架里，Map之后的数据是要经过排序才执行Reduce操作的。想想归并排序算法的思想，对小文件进行排序，然后将小文件归并成大文件的思想。如果数据块很大，排序就变慢了。 2.1.4. 数据块副本每个块有多个副本，存储在不同的DataNode上。副本数默认为3 2.1.5. 数据块副本存放策略假设数据块有三个副本： 第一个副本：放置在本地机架的节点上（就近原则）；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点 第二个副本：放置在与第一个副本不同的机架的节点上。因为同一个机架一般使用同一个电源，电源挂掉则整个机架的服务器都挂掉。所以要放在另一个机架的节点上。 第三个副本：与第二个副本相同机架的其他节点上。因为前2个副本已经分别存放在位于两个不同机架的节点上，安全性已经得到一定的保证。同一个机架的节点一般连接同一个高速交换机，所以现在把第3个副本放到与第2个副本相同的机架上，还保证了数据的快速传输。 如果有更多的其它副本：则挑选随机节点 2.1.6. 数据块损坏（corruption）处理情况1：client读取数据时 客户端请求DataNode读取数据块，DataNode读取block时，会计算该block的checksum 如果计算得到的checksum，与block创建时的值不一样，说明block已经损坏 client得知该block已经损坏，会读取其它DataNode上的副本块 下一次DataNode向NameNode发送块列表报告时，NameNode得知该数据块已经损坏，会复制该block的副本，达到预设的副本数 情况2：DataNode会自动在其文件创建后三周验证其checksum，处理同上。 2.1.7. 验证每个数据块有两个文件dfs/data/ 是HDFS数据的存储路径。可以看到每个数据块有两份文件，一个是数据本身，一个是元数据。 12345678910111213141516171819202122$ tree /usr/local/hadoop/tmp/dfs/data//usr/local/hadoop/tmp/dfs/data/├── current│ ├── BP-798495748-192.168.57.100-1550512504378│ │ ├── current│ │ │ ├── dfsUsed│ │ │ ├── finalized│ │ │ │ └── subdir0│ │ │ │ └── subdir0│ │ │ │ ├── blk_1073741825 # 数据文件│ │ │ │ ├── blk_1073741825_1003.meta # 元数据文件│ │ │ │ ├── blk_1073741826│ │ │ │ ├── blk_1073741826_1004.meta│ │ │ │ ├── blk_1073741827│ │ │ │ └── blk_1073741827_1005.meta│ │ │ ├── rbw│ │ │ └── VERSION│ │ ├── dncp_block_verification.log.curr│ │ ├── dncp_block_verification.log.prev│ │ └── tmp│ └── VERSION└── in_use.lock 2.2. HDFS命名空间管理HDFS的命名空间包含目录、文件和数据块 HDFS使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等。 注意：只能在文件中追加信息，但是不能修改文件内容。 2.3. NameNode（NN）NameNode是整个HDFS的管家 管理整个HDFS的元数据（MetaData） 管理客户端对HDFS的访问。客户端读写数据实际是自己到DataNode上操作的，但是要先与NameNode交互，得到元数据信息（数据在哪些DataNode上）。NameNode会根据全局情况做出决定，客户端读取数据时，NameNode尽量让客户端读取最近的副本。 决定数据块副本存放在哪些DataNode上。 周期性从每个DataNode接收心跳信号和块状态报告（BlockReport）。块状态报告包含了该DataNode上所有的数据块列表信息。 NameNode保存了两个核心的数据结构，即FsImage（保存HDFS元数据）和EditLog（保存HDFS操作日志） FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据- EditLog中记录了所有针对文件的创建、删除、重命名等操作 2.3.1. FsImage和EditLog元数据在NameNode内存中有一份，同时还要写到磁盘上，文件名为FsImage FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据。 FsImage文件没有记录块存储在哪个数据节点。而是由名称节点把这些映射保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，直接加载到NameNode的内存中，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。 元数据发生改变时，不会立即同步到FsImage文件，而是在edits记录元数据的操作日志。经过一段时间后，再由SecondaryNameNode将edits中的内容合并到FsImage中 2.3.2. NameNode需要格式化NameNode一开始需要格式化，目的是生成FsImage 1hdfs namenode -format 2.3.3. NameNode启动过程NameNode启动过程： 读取fsimage和editlog到内存中 执行editlog的各项操作，更新内存中的元数据，存在内存中的元数据支持客户端的读操作 将内存中的元数据写到新的fsimage文件中 创建一个新的空的editlog文件。同时启动HDFS的安全模式 启动DataNode 向NameNode注册 发送BlockReport。发送完之后，关闭HDFS的安全模式。 之后HDFS的所有操作都记录到新的editlog中 HDFS的安全模式（SafeMode）： 等待DataNode向NameNode发送BlockReport。在安全模式期间，客户端只能读取HDFS，但是不能写HDFS（创建文件夹、上传文件、删除文件 都不能操作）。 汇总所有的BlockReport。一开始NameNode加载完fsimage和editlog时，就得知整个文件系统总共有多少个block（total blocks）。从不断接收到的BlockReport中，不断累计得到所有的DataNode上总共有多少block（reported blocks）。计算 reported blocks / total blocks，如果比值 &gt;= 99.9%，安全模式才会退出。 安全模式退出后，客户端就能对HDFS执行写操作了。 2.3.4. 验证安全模式的存在关闭HDFS所有服务，只启动namenode 1hadoop-daemon.sh start namenode 查看namenode的web ui，可以看到NameNode处于SafeMode。 total blocks有3个，接收到的reported blocks只有0个 只有当 reported blocks / total blocks &gt;= 0.9990，才会关闭SafeMode 启动datanode 1hadoop-daemon.sh start datanode 启动后，在短时间内再次查看namenode的web ui，可以看到NameNode仍处于SafeMode。total blocks有3个，接收到的reported blocks也有3个，所以 reported blocks / total blocks = 1 &gt;= 0.9990，已经触发了关闭SafeMode的条件。因此在30秒之后，NameNode将自动关闭SafeMode 经过30秒后，再次查看namenode的web ui 2.3.5. 为什么达到关闭SafeMode的条件，还要缓冲30秒？服务器求稳不求快，给30秒让HDFS稳定一下 2.3.6. 手动操作SafeMode1234hdfs dfsadmin -safemode get # 查看是否处于安全模式hdfs dfsadmin -safemode enter # 手动进入安全模式hdfs dfsadmin -safemode leave # 强制退出安全模式hdfs dfsadmin -safemode wait # 挂起shell，直到安全模式退出 2.4. DataNode 负责数据的存储和读写 DataNode启动后向NameNode注册，通过后，周期性（1小时）向NameNode上报块列表信息 每3秒一次向NameNode发送心跳，心跳返回结果带有NameNode给DataNode命令（如复制块数据到另一台机器，或删除某个数据块）。如果NameNode超过10分钟没有收到某个DataNode，则认为该DataNode不可用。 2.5. SecondaryNameNode（SNN）SecondaryNameNode的作用： 辅助NameNode合并fsimage和editlog 辅助合并fsimage和editlog时，会在本地保留一份fsimage.ckpt，所以还起到元数据冷备份的作用 即使SecondaryNameNode不启动，HDFS也能正常工作 2.5.1. 为什么要辅助NameNode合并fsimage和editlog假如HDFS起来之后，几个月都没有停止、重启。如果操作了很多数据，editlog就会非常大，下一次NameNode重启时，读取editlog要花很多时间。 此时就需要SecondaryNameNode，每隔一段时间（当然触发情况不止是这一个），就去帮助NameNode合并fsimage和editlog，生成新的fsimage，再把新的fsimage复制给NameNode。 这样下一次NameNode重启时，editlog就不会特别大，读取editlog不用花太多时间，就加快了NameNode的启动时间。 2.5.2. SecondaryNameNode触发合并的情况 情况1：根据配置文件设置的时间间隔fs.checkpoint.period 默认3600秒（1小时）。 情况2：根据配置文件设置EditsLog大小 fs.checkpoint.size 规定edits文件的最大值默认是64MB 2.5.3. 合并流程 当edits文件的大小达到一个临界值(默认是64MB)或者间隔一段时间(默认是1小时)的时候checkpoint会触发SecondaryNameNode进行合并工作。 当触发一个checkpoint操作时，NameNode会生成一个新的edits即上图中的edits.new文件，之后元数据的改变都会写入edits.new文件中，而不是原来的edits文件。 SecondaryNameNode会将NameNode的edits文件和FsImage下载到本地。 SecondaryNameNode将本地的FsImage文件加载到内存中，然后再与edits文件进行合并生成一个新的FsImage文件即上图中的FsImage.ckpt文件。 SecondaryNameNode将新生成的FsImage.ckpt文件发送到NameNode节点。 NameNode结点的edits.new文件和FsImage.ckpt文件会替换掉原来的edits文件和FsImage文件，至此，刚好是一个轮回即在NameNode中又是edits和FsImage文件了。 等待下一次checkpoint触发SecondaryNameNode进行工作，一直这样循环操作。 以上过程既实现了FsImage和EditsLog的合并。因为其间名称节点的元数据被拷贝到第二名称节点上，所以说起到冷备份的效果。 3. HDFS安全机制3.1. HDFS副本]]></content>
      <categories>
        <category>Hadoop</category>
        <category>HDFS</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MapReduce 概述]]></title>
    <url>%2F2019%2F02%2F20%2Fhadoop%2FMapReduce%20%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[1. YARN架构 1.1. 各个组件的作用ResourceManager 处理客户端请求 启动/监控ApplicationMaster 监控NodeManager 资源分配与调度 NodeManager 单个节点上的资源管理 处理来自ResourceManager的命令 处理来自ApplicationMaster的命令 ApplicationMaster 数据切分 为应用程序申请资源，并分配给内部任务 任务监控与容错 Container 对任务运行环境的抽象，封装了CPU内存等多维资源以及环境变量、启动命令等任务运 行相关的信息. Map、Reduce等任务都是运行在Container上 1.2. ResourceManagerResourceManager是全局的资源管理器，整个集群只有一个，负责集群资源的统一管理和调度分配。 1.2.1. ResourceManager的功能 处理客户端请求 启动/监控ApplicationMaster 监控NodeManager 资源分配与调度 1.3. NodeManagerNodeManager可以有多个节点，负责单个节点资源管理和使用 NodeManager一般与DataNode在同一个节点 NodeManager的功能： 单个节点上的资源管理 处理来自ResourceManager的命令 处理来自ApplicationMaster的命令 NodeManager管理抽象容器Container，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源 NodeManager定时地向RM汇报节点上的资源使用情况和各个Container的运行状态 1.4. Application Master管理一个在YARN内运行的应用程序的每个实例 功能： 数据切分 为应用程序申请资源，并分配给内部任务 任务监控与容错 负责协调来自ResourceManager的资源，开通过NodeManager监视容器的执行和资源使用（CPU,内存等的资源分配） 1.5. ContainerYARN中的资源抽象，封装某个节点上多维度资源，如内存，CPU,自盘，网络等，当AM想RM申请资源时，RM向AM返回的资源便是用Container表示的 YARN 会为每个任务分配一个Container,且该任务只能使用Container中描述的资源 2. YARN 资源管理资源调度和资源隔离是YARN作为一个资源管理系统，最重要和最基础的两个功能。 资源调度由ResourceManager完成 资源隔离由各个NodeManager实现 ResourceManager将某个NodeManager上资源分配给任务（这就是所谓的”资源调度”）后，NodeManager需按照要求为任务提供相应的资源，甚至保证这些资源应具有独占性，为任务运行提供基础的保证，这就是所谓的资源隔离。 当谈及到资源时，我们通常指内存，CPU和IO三种资源。Hadoop YARN同时支持内存和CPU两种资源的调度。 内存资源的多少会会决定任务的生死，如果内存不够，任务可能运行失败；相比之下，CPU资源则不同，它只会决定任务运行的快慢，不会对生死产生影响。 YARN允许用户配置每个节点上可用的物理内存资源，注意，这里是“可用的”，因为一个节点上的内存会被若干个服务共享，比如一部分给YARN，一部分给HDFS，一部分给HBase等，YARN配置的知识自己可以使用的，配置参数如下： yarn.nodemanager.resource.memory-mb表示该节点上YARN可使用的物理内存总量，默认是8192（MB），注意，如果你的节点内存资源不够8GB,则需要调减这个值，而YARN不会只能的探测节点的物理内存总量。 yarn.nodemanager.vmem-pmem-ratio任务每使用1MB物理内存，最多可使用虚拟内存量，默认是2.1 yarn.nodemanager.pmem-check-enabled是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true。 yarn.nodemanager.vmem-check-enabled是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true。 yarn.scheduler.minimum-allocation-mb单个任务可申请的最少物理内存量，默认是1024(MB),如果一个任务申请的物理内存量少于该值，则该对应的值改为这个数。 yarn.scheduler.maximum-allocation-mb单个任务可申请的最多物理内存量，默认是8192（MB）. 目前的CPU被划分成虚拟CPU（CPU virtual Core）,这里的虚拟CPU是YARN自己引入的概念，初衷是，考虑到不同节点的CPU性能可能不同，每个CPU具有的计算能力也是不一样的，比如某个物理CPU的计算机能力可能是另外一个物理CPU的2倍，这时候，你可以通过为第一个物理CPU多配置几个虚拟CPU弥补这种差异。用户提交作业时，可硬指定没干过任务需要的虚拟CPU个数。在YARN中，CPU相关配置参数如下： yarn.nodemanager.resource.cpu-vcores表示该节点上YANR可使用的虚拟CPU个数，默认是8，注意，目前推荐将该为与物理CPU核数数目相同。如果你的节点CPU核数不够8个，则需要调减小这个值，而YARN不会智能的探测节点的物理CPU总数。 yarn.scheduler.minimum-allocation-vcore单个任务可申请的最小虚拟CPU个数，默认是1，如果一个任务申请的CPU个数少于该数，则该对应的值改为这个数。 yarn.scheduler.maximum-allocation-vcores 单个任务可申请的最大虚拟CPU个数 3. MapReduce架构离线计算框架 MapReduce 将计算过程分为两个阶段，map和reduce map 阶段并行处理输入数据 reduce 阶段对map 结果进行汇总。 shuffle 连接map 和Reduce 两个阶段 map task 将数据写到本地磁盘 reduce task 从每个map TASK 上读取一份数据 仅适合 离线批处理 具有很好的容错性和扩展性 适合简单的批处理任务 缺点明显 启动开销大，过多使用磁盘导致效率底下等。 4. MapReduce On YARN 客户端向YARN中提交应用程序/作业给ResourceManager，其中包括ApplicaitonMaster程序、启动ApplicationMaster的命令、用户程序等； ResourceManager为作业分配第一个Container，并与对应的NodeManager通信，要求它在这个Containter中启动该作业的ApplicationMaster（App Mstr）； ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查询作业的运行状态；然后它将为各个任务申请资源并监控任务的运行状态，直到运行结束。即重复步骤4-7； ApplicationMaster采用轮询的方式通过RPC请求向ResourceManager申请和领取资源； 一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务； 各个NodeManager分别在Container中启动Map任务（Map Task），或者启动Reduce任务（Reduce Task），或者都启动（如果本机资源足够的话）； 各个任务通过RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicaitonMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务； 在作业运行过程中，用户可随时通过RPC向ApplicationMaster查询作业当前运行状态； 作业完成后，ApplicationMaster向ResourceManager注销并关闭自己；]]></content>
      <categories>
        <category>Hadoop</category>
        <category>MapReduce</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 概述]]></title>
    <url>%2F2019%2F02%2F20%2Fhadoop%2FHadoop%20%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[1. 什么是hadoop⭐ Hadoop是一个由Apache基金会所开发的分布式系统基础架构 主要解决海量数据的存储和分析计算问题。 广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈 1.1. hadoop核心组件它包括三部分：HDFS，YARN，和MapReduce 组件 描述 功能 HDFS Hadoop分布式文件系统 分布式存储海量数据集 MapReduce 基于YARN分布式并行处理海量数据集 分布式计算海量数据集 YARN 任务调度和集群资源管理框架 任务调度、资源管理 1.2. hadoop狭义与广义狭义hadoop：大数据分布式存储（HDFS） + 分布式计算 + 资源调度（YARN）框架。 广义hadoop：指hadoop生态系统（生态圈）。hadoop框架是其中最重要最基础的一个部分。生态系统中的每一个子系统只能解决某一个领域的特定问题域。 HDFS：分布式文件系统MapReduce：分布式运算程序开发框架Hbase：基于HADOOP的分布式海量数据库，离线分析和在线业务通吃Hive：基于大数据技术（文件系统+运算框架）的SQL数据仓库工具，使用方便，功能丰富，基于MR延迟大Sqoop：数据导入导出工具Flume：数据采集框架ZOOKEEPER：分布式协调服务基础组件Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库Oozie：工作流调度框架Sqoop：数据导入导出工具Flume：日志数据采集框架 2. Hadoop发展历史1）Lucene——Doug Cutting开创的开源软件，用java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 2）2001年年底成为apache基金会的一个子项目 3）对于大数量的场景，Lucene面对与Google同样的困难 4）学习和模仿Google解决这些问题的办法 ：微型版Nutch 5）可以说Google是hadoop的思想之源(Google在大数据方面的三篇论文) GFS —&gt;HDFSMapReduce —&gt;MapReduceBigTable —&gt;HBase 6）2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，使Nutch性能飙升 7）2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 8）名字来源于Doug Cutting儿子的玩具大象 9）Hadoop就此诞生并迅速发展，标志这云计算时代来临 3. Hadoop三大发行版本Hadoop三大发行版本：Apache、Cloudera、Hortonworks。 Apache版本最原始（最基础）的版本，对于入门学习最好 Cloudera在大型互联网企业中用的较多。使用免费，解决问题收费 Hortonworks文档较好。使用免费，解决问题收费 3.1. Apache Hadoop官网地址：http://hadoop.apache.org/releases.html 下载地址：https://archive.apache.org/dist/hadoop/common/ 3.2. Cloudera Hadoop官网地址：https://www.cloudera.com/downloads/cdh/5-10-0.html 下载地址：http://archive-primary.cloudera.com/cdh5/cdh/5/ 全称 Cloudera’s Distribution Including Apache Hadoop（简称CDH） （1）2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。 （2）2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support （3）CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强。 （4）Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。 （5）Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。 3.3. Hortonworks Hadoop官网地址：https://hortonworks.com/products/data-center/hdp/ 下载地址：https://hortonworks.com/downloads/#data-platform （1）2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。 （2）公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop 80%的代码。 （3）雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。 （4）Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。 （5）HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。 （6）Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的Microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。 4. Hadoop的优势（4高）1）高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。2）高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。3）高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。4）高容错性：能够自动将失败的任务重新分配。 5. Hadoop各版本区别 Hadoop1.0 MapReduce不仅要处理数据，还要管理集群资源 Hadoop2.0 YARN成为Hadoop的操作系统。任务调度和集群资源管理由YARN负责。 在YARN上可以运行各种数据处理框架。不仅能运行原来的批处理框架MapReduce，还能运行流式处理框架Storm、内存计算框架Spark等等 ​]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[文章标题]]></title>
    <url>%2F2019%2F02%2F19%2F%E6%96%87%E7%AB%A0%E6%A0%87%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 这里是文章内容1.1 这里是文章内容 这里是文章内容这里是文章内容 haha123456789这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容 这里是文章内容这里是文章内容 这里是文章内容这里是文章内容 123456789这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容 这里是文章内容这里是文章内容 这里是文章内容这里是文章内容 123456789这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容 这里是文章内容这里是文章内容 这里是文章内容这里是文章内容 123456789这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容这里是文章内容]]></content>
      <categories>
        <category>后端</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>
